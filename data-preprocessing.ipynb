{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征编码和数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思路\n",
    "数据增强，例如把一些矩阵的一部分提取出来作为数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型设计思路\n",
    "1. 特征工程\n",
    "基因表达量：将FPKM或TPM值作为特征。\n",
    "位置信息：将基因的染色体位置（包括起始和终止位置）考虑进来。这可以通过直接使用这些数值或将它们转换为基因长度等派生特征来实现。\n",
    "2. 序列模型或图模型\n",
    "序列模型：如果你认为基因在染色体上的顺序是重要的，可以考虑使用序列模型（如LSTM或Transformer）。这要求将每个细胞的基因按照染色体位置排序，然后用序列模型来处理排序后的序列。\n",
    "\n",
    "图模型：考虑到基因之间可能存在的相互作用，可以使用图神经网络（GNN）来建模基因之间的关系。在这种情况下，每个基因可以作为图中的一个节点，而节点之间的边可以基于基因间的物理距离或已知的功能关联。\n",
    "\n",
    "3. 自定义模型结构\n",
    "组合模型：可以设计一个模型，该模型结合了传统的全连接层、序列处理层（如LSTM或Transformer层）和/或图层（如果使用GNN）。例如，可以先用一个序列或图模型处理基因表达数据和位置信息，然后将这些模型的输出连接到一个或多个全连接层以进行最终的分类。\n",
    "数据准备\n",
    "考虑到每个样本是一个单独的表格，你需要将这些表格转换为统一格式的数据，这可能意味着：\n",
    "\n",
    "标准化基因列表：确保每个样本表格包含相同的基因集，这可能需要填充缺失的基因表达量（例如，使用0或基因表达量的平均值）。\n",
    "特征编码：将染色体位置编码为可用的数值特征，例如通过计算基因的长度或将染色体编号转换为独热编码。\n",
    "实现建议\n",
    "数据预处理：编写脚本来预处理每个样本的数据，确保它们具有统一的格式和特征集。\n",
    "模型选择：基于你对数据的理解和任务的需求，选择适当的模型架构。PyTorch提供了灵活的API来构建自定义模型，而Fastai可以简化训练流程。\n",
    "训练和验证：训练模型时，可能需要特别注意防止过拟合，特别是当样本数量相对于特征数量较少时。使用适当的正则化技术和验证策略来评估模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# 假定的数据根目录\n",
    "data_root = 'E:\\RNA-data\\PRJNA494560'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subdirectories: 148\n",
      "Number of subdirectories in each directory:\n",
      "Adrenal gland: 5\n",
      "Bladder: 5\n",
      "Brain (mixed white and gray matter): 8\n",
      "CD138+ enriched bone marrow cells: 9\n",
      "Cervix: 2\n",
      "Cervix, endometrium: 2\n",
      "Colon: 3\n",
      "Colon, epithelium: 5\n",
      "Esophagus: 10\n",
      "Kidney: 7\n",
      "Liver: 10\n",
      "Lung: 8\n",
      "Mammary gland: 5\n",
      "Ovary: 4\n",
      "Pancreas: 7\n",
      "Prostate: 6\n",
      "Skeletal muscle: 6\n",
      "Skin: 6\n",
      "Small intestine: 6\n",
      "Stomach: 13\n",
      "Thyroid gland: 6\n",
      "Tonsil: 7\n",
      "Uterus (myometrium): 2\n",
      "Whole blood nuclear cells: 6\n"
     ]
    }
   ],
   "source": [
    "total_subdirs = 0\n",
    "subdirs_per_dir = {}\n",
    "\n",
    "for root, dirs, files in os.walk(data_root):\n",
    "    if root == data_root:  # 只在顶层目录计算子目录数量\n",
    "        for dir in dirs:\n",
    "            subdir_count = len([name for name in os.listdir(os.path.join(root, dir)) if os.path.isdir(os.path.join(root, dir, name))])\n",
    "            subdirs_per_dir[dir] = subdir_count\n",
    "            total_subdirs += subdir_count\n",
    "\n",
    "print(f\"Total subdirectories: {total_subdirs}\")\n",
    "print(\"Number of subdirectories in each directory:\")\n",
    "for dir, count in subdirs_per_dir.items():\n",
    "    print(f\"{dir}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存每个文件路径和对应组织类型的信息\n",
    "sample_files = []\n",
    "\n",
    "# 遍历数据目录，收集每个样本文件的路径\n",
    "for root, dirs, files in os.walk(data_root):\n",
    "    for file in files:\n",
    "        if file.endswith('_gene_abundances.tsv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            sample_files.append(file_path)\n",
    "\n",
    "len(sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理质量低的数据\n",
    "\n",
    "# import os\n",
    "\n",
    "# # 存储低于20%的log文件\n",
    "# low_percentage_logs = []\n",
    "\n",
    "# # 遍历dataroot路径下的所有文件\n",
    "# for root, dirs, files in os.walk(data_root):\n",
    "#     for file in files:\n",
    "#         # 检查文件是否为log文件\n",
    "#         if file.endswith('.log'):\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             # 读取文件的最后一行\n",
    "#             with open(file_path, 'r') as f:\n",
    "#                 last_line = f.readlines()[-1]\n",
    "#                 # 提取最后一行中的百分比值\n",
    "#                 percentage = float(last_line.split('%')[0])  # 假设百分比值在最后一行的形式为 'xx%'\n",
    "#                 # 检查百分比值是否低于20%\n",
    "#                 if percentage < 20:\n",
    "#                     low_percentage_logs.append(file_path)\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# # 目标目录\n",
    "# target_dir = 'E:\\\\RNA-data\\\\less_than20'\n",
    "\n",
    "# # 遍历低于20%的log文件\n",
    "# for log in low_percentage_logs:\n",
    "#     # 获取log文件的目录\n",
    "#     log_dir = os.path.dirname(log)\n",
    "#     # 创建目标目录，保留原来的路径结构\n",
    "#     target_log_dir = os.path.join(target_dir, os.path.relpath(log_dir, data_root))\n",
    "#     os.makedirs(target_log_dir, exist_ok=True)\n",
    "    \n",
    "#     # 移动log文件所在目录的所有文件到目标目录\n",
    "#     for file_name in os.listdir(log_dir):\n",
    "#         shutil.move(os.path.join(log_dir, file_name), target_log_dir)\n",
    "\n",
    "\n",
    "# # 遍历低于20%的log文件\n",
    "# for log in low_percentage_logs:\n",
    "#     # 获取log文件的目录\n",
    "#     log_dir = os.path.dirname(log)\n",
    "#     # 删除原来的log文件所在的文件夹\n",
    "#     shutil.rmtree(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个集合，用于存储第一个文件的基因唯一标识符\n",
    "first_file = sample_files[0]\n",
    "df_first = pd.read_csv(first_file, sep='\\t')\n",
    "unique_genes = set(df_first[['Gene ID', 'Start', 'End']].apply(tuple, axis=1))\n",
    "\n",
    "# 遍历其余的文件\n",
    "for file in sample_files[1:]:\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    # 对每个文件，将'Gene ID', 'Start', 'End'列组合作为唯一标识符\n",
    "    current_genes = set(df[['Gene ID', 'Start', 'End']].apply(tuple, axis=1))\n",
    "    # 找出所有文件中这些唯一标识符的交集\n",
    "    unique_genes = unique_genes.intersection(current_genes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60662"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ENSG00000269845', 21750747, 21753438)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_genes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming unique_genes is a set of tuples, where each tuple is (Gene ID, Start, End)\n",
    "\n",
    "for file in sample_files:\n",
    "    # Read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    \n",
    "    # Convert the 'Gene ID', 'Start', 'End' columns to a set of tuples\n",
    "    file_genes = set(df[['Gene ID', 'Start', 'End']].itertuples(index=False, name=None))\n",
    "    \n",
    "    # Find the intersection of the file's genes and the unique genes\n",
    "    common_genes = file_genes & unique_genes\n",
    "    \n",
    "    # Filter the DataFrame to only include the common genes\n",
    "    df_common = df[df[['Gene ID', 'Start', 'End']].apply(tuple, axis=1).isin(common_genes)]\n",
    "    \n",
    "    # Sort the DataFrame\n",
    "    df_sorted = df_common.sort_values(by=['Gene ID', 'Start', 'End'])\n",
    "    \n",
    "    # Write the sorted DataFrame back to the file\n",
    "    df_sorted.to_csv(file.replace('_gene_abundances.tsv', '_gene_abundances_preprocessed.tsv'), sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "old_root = 'E:\\\\RNA-data\\\\PRJNA494560'\n",
    "new_root = 'D:\\\\OneDrive - whu.edu.cn\\\\文档 - 人工智能与RNA剪接\\\\PRJNA494560'\n",
    "\n",
    "# 遍历 old_root 下的所有文件\n",
    "for dirpath, dirnames, filenames in os.walk(old_root):\n",
    "    for filename in filenames:\n",
    "        # 检查文件是否为预处理的 tsv 文件\n",
    "        if filename.endswith('_abundances.tsv'):\n",
    "            # 获取旧文件的完整路径\n",
    "            old_file_path = os.path.join(dirpath, filename)\n",
    "            # 创建新的文件路径\n",
    "            new_file_path = old_file_path.replace(old_root, new_root)\n",
    "            # 创建新文件路径中的所有目录\n",
    "            os.makedirs(os.path.dirname(new_file_path), exist_ok=True)\n",
    "            # 将文件复制到新的位置\n",
    "            shutil.copy2(old_file_path, new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 假设data_path是包含所有TSV文件的目录路径\n",
    "data_path = 'E:\\RNA-data\\PRJNA494560'\n",
    "# 保存每个文件路径和对应组织类型的信息\n",
    "files = []\n",
    "\n",
    "# 遍历数据目录，收集每个样本文件的路径\n",
    "for root, dirs, filess in os.walk(data_path):\n",
    "    for file in filess:\n",
    "        if file.endswith('_preprocessed.tsv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            files.append(file_path)\n",
    "\n",
    "# 初始化一个空的DataFrame来存储整合后的数据\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# 初始化一个列表来存储每个样本的标签\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    # 根据你的文件结构调整路径和提取标签的方式\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    label = file_path.split('\\\\')[-3]  # 假设标签存储在父目录名称中\n",
    "    labels.append(label)\n",
    "    \n",
    "    # 读取TSV文件\n",
    "    df = pd.read_csv(file_path, sep='\\t', usecols=['Gene ID', 'TPM'])\n",
    "    \n",
    "    # 转换为每个基因一个列的形式\n",
    "    df = df.pivot_table(index='Gene ID', values='TPM').T\n",
    "    \n",
    "    # 将当前样本的数据追加到总DataFrame中\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True, sort=False)\n",
    "\n",
    "# # 用0填充缺失值\n",
    "# all_data = all_data.fillna(0)\n",
    "\n",
    "# 添加标签列\n",
    "all_data['Label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data.tsv',sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
